{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd5f910",
   "metadata": {},
   "source": [
    "# DROPPING DATAPOINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f9dd0",
   "metadata": {},
   "source": [
    "import packages : pandas\n",
    "\n",
    "input file : final_cleaned_data.csv\n",
    "\n",
    "stage 0 : typeconversion (all datatypes are either String or Int64)\n",
    "\n",
    "stage 1 : drop all properties without prices or priced smaller than 25.000 €\n",
    "\n",
    "stage 2 : drop all subtypes that are not houses or apartments\n",
    "\n",
    "stage 3 : keep only properties with living area between 10 m² and 40.000 m²\n",
    "\n",
    "stage 4 : drop all properties with terraces over 150m²\n",
    "\n",
    "output file: filtered_final_cleaned_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d29114",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'final_cleaned_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#load input file into dataframe\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfinal_cleaned_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m total_before = df.shape[\u001b[32m0\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_datatypes\u001b[39m(df):\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# converting float to int\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repo\\immo-eliza-racoons-analysis\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repo\\immo-eliza-racoons-analysis\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repo\\immo-eliza-racoons-analysis\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repo\\immo-eliza-racoons-analysis\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repo\\immo-eliza-racoons-analysis\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'final_cleaned_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load input file into dataframe\n",
    "df = pd.read_csv(\"final_cleaned_data.csv\")\n",
    "total_before = df.shape[0]\n",
    "\n",
    "def convert_datatypes(df):\n",
    "\n",
    "    # converting float to int\n",
    "    df = df.apply(lambda x: x.astype(\"Int64\") if x.dtype == float and (x.dropna() % 1 == 0).all() else x)\n",
    "\n",
    "    # converting objects to strings\n",
    "    df['property_ID'] = df['property_ID'].astype('string')\n",
    "    df['locality_name'] = df['locality_name'].astype('string')\n",
    "    df['type'] = df['type'].astype('string')\n",
    "    df['subtype'] = df['subtype'].astype('string')\n",
    "    df['state_of_building'] = df['state_of_building'].astype('string')\n",
    "    return df\n",
    "\n",
    "def drop_prices(df):\n",
    "    #check number of rows in initial list\n",
    "    before_drop = df.shape[0]\n",
    "\n",
    "    # removing properties that do not have the price and are priced below 25K\n",
    "    df = df.dropna(subset=[\"price (€)\"])\n",
    "    df = df[(df['price (€)'] >= 25000)]\n",
    "    print (\"dropped\", before_drop - df.shape[0], \"properties with a price less than 25K or no price\") \n",
    "\n",
    "    return df\n",
    "\n",
    "def drop_subtypes (df):\n",
    "    #check number of rows in initial list\n",
    "    before_drop = df.shape[0]\n",
    "    #print(df.shape[0])\n",
    "    #make a list of what subtypes we want to keep\n",
    "    allowed = [\n",
    "        \"Apartment\", \"Residence\", \"Villa\", \"Ground floor\", \"Penthouse\",\n",
    "        \"Mixed building\", \"Duplex\", \"Studio\", \"Chalet\", \"Master house\",\n",
    "        \"Bungalow\", \"Cottage\", \"Loft\", \"Triplex\", \"Mansion\"]\n",
    "\n",
    "    # filter the subtypes we want to keep\n",
    "    df = df[df['subtype'].isin(allowed)]\n",
    "\n",
    "    #how many dropped?\n",
    "    print(\"dropped\",before_drop-df.shape[0],\"properties with wrong subtypes\")\n",
    "    return (df)\n",
    "\n",
    "def drop_living_area(df):\n",
    "    #check number of rows in initial list\n",
    "    before_drop = df.shape[0]\n",
    "\n",
    "    # filter df: remove all houses under 10m² and above 400000\n",
    "    df = df[(df['living_area (m²)'] >= 10) & (df['living_area (m²)'] < 40000)]\n",
    "\n",
    "    #how many dropped?\n",
    "    print(\"dropped\",before_drop-df.shape[0],\"properties with abnormal living areas\")\n",
    "    return(df)\n",
    "\n",
    "def drop_terrace_area(df):\n",
    "    #check number of rows in initial list\n",
    "    before_drop = df.shape[0]\n",
    "\n",
    "    # filter df: remove all terraces above 150m²\n",
    "    df = df[(df['terrace_area (m²)'].isna()) | (df['terrace_area (m²)'] <= 150)]\n",
    "\n",
    "    #how many dropped?\n",
    "    print(\"dropped\",before_drop-df.shape[0],\"properties with abnormal terraces\")\n",
    "    return(df)\n",
    "\n",
    "\n",
    "#stage 0: typeconverion\n",
    "df = convert_datatypes(df)\n",
    "\n",
    "#stage 1: drop prices\n",
    "df = drop_prices(df)\n",
    "\n",
    "#stage 2: drop subtypes\n",
    "df = drop_subtypes(df)\n",
    "\n",
    "#stage 3: drop living areas\n",
    "df = drop_living_area(df)\n",
    "\n",
    "#stage 4: drop_terrace areas\n",
    "df = drop_terrace_area(df)\n",
    "\n",
    "print(\"a total of\", total_before - df.shape[0], \"properties were dropped\")\n",
    "\n",
    "#write to output file\n",
    "df.to_csv(\"filtered_final_cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68066c8",
   "metadata": {},
   "source": [
    "# DISTRIBUTIONS & OUTLIER ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca4bb5f",
   "metadata": {},
   "source": [
    "# missing values filtered dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0008ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (FARANGES)\n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "# Put the missing values per column in percentage\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Values': df.isnull().sum(),\n",
    "    'Percentage (%)': (df.isnull().sum() / len(df)) * 100\n",
    "})\n",
    "\n",
    "# Round off the percentages\n",
    "missing_summary['Percentage (%)'] = missing_summary['Percentage (%)'].round(0)\n",
    "display(missing_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4884cfd",
   "metadata": {},
   "source": [
    "# distribution of type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#show bar chart of categories\n",
    "df['type'].value_counts().plot(kind='barh')\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.title(\"Distribution per type\")\n",
    "plt.show()\n",
    "\n",
    "#how many different values and how much are there?\n",
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a847b8",
   "metadata": {},
   "source": [
    "# distribution of subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98fdd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show bar chart of categories\n",
    "df['subtype'].value_counts().plot(kind='barh')\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.title(\"Distribution per subtype\")\n",
    "plt.show()\n",
    "\n",
    "#how many different values and how much are there?\n",
    "df[\"subtype\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32048717",
   "metadata": {},
   "source": [
    "# distribution of price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 8))\n",
    "\n",
    "# --- Plot boxplot ---\n",
    "sns.boxplot(data=df, y=\"price (€)\", ax=ax)\n",
    "\n",
    "# --- Compute whiskers and outliers ---\n",
    "prices = df[\"price (€)\"]\n",
    "Q1 = prices.quantile(0.25)\n",
    "Q3 = prices.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "# Outliers\n",
    "outliers = prices[prices > upper_whisker]\n",
    "n_outliers = len(outliers)\n",
    "\n",
    "# --- Draw ellipse around outliers ---\n",
    "# Choose ellipse size based on plot y-limits\n",
    "ymin, ymax = ax.get_ylim()\n",
    "\n",
    "ellipse_height = (ymax - upper_whisker) * 0.95\n",
    "ellipse_width = 0.35    # works well for vertical boxplots\n",
    "ellipse_center_x = 0     # x=0 is where the boxplot is drawn\n",
    "ellipse_center_y = upper_whisker + ellipse_height / 2\n",
    "\n",
    "ellipse = patches.Ellipse(\n",
    "    (ellipse_center_x, ellipse_center_y),\n",
    "    ellipse_width,\n",
    "    ellipse_height,\n",
    "    edgecolor='red',\n",
    "    facecolor='none',\n",
    "    linewidth=2\n",
    ")\n",
    "ax.add_patch(ellipse)\n",
    "\n",
    "# --- Add text label ---\n",
    "ax.text(\n",
    "    ellipse_center_x,\n",
    "    ellipse_center_y,\n",
    "    f\"{n_outliers} outliers\",\n",
    "    color='red',\n",
    "    ha='center',\n",
    "    va='center',\n",
    "    fontsize=12,\n",
    "    weight='bold'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRICE for houses less than 1M\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "# make a new df without houses over 1M\n",
    "df_cheaper = df[(df[\"price (€)\"]) <= 1000000]\n",
    "\n",
    "\n",
    "# visual upgraded boxplot houses < 1M\n",
    "ax = sns.boxplot(data=df_cheaper, y=\"price (€)\")\n",
    "\n",
    "# Extract values\n",
    "prices = df_cheaper[\"price (€)\"]\n",
    "median = prices.median()\n",
    "whisker_low = np.percentile(prices, 25) - 1.5 * (np.percentile(prices, 75) - np.percentile(prices, 25))\n",
    "whisker_high = np.percentile(prices, 75) + 1.5 * (np.percentile(prices, 75) - np.percentile(prices, 25))\n",
    "\n",
    "# But real whiskers are clipped to the actual data range:\n",
    "whisker_low = prices[prices >= whisker_low].min()\n",
    "whisker_high = prices[prices <= whisker_high].max()\n",
    "\n",
    "#add title\n",
    "plt.title(\"Distribution of Price\", fontsize=14)\n",
    "\n",
    "# Annotate\n",
    "ax.annotate(f\"Median: {median:,.0f} €\", xy=(0, median),\n",
    "            xytext=(0.1, median), color=\"black\")\n",
    "\n",
    "ax.annotate(f\"Low whisker: {whisker_low:,.0f} €\", xy=(0, whisker_low),\n",
    "            xytext=(0.1, whisker_low), color=\"blue\")\n",
    "\n",
    "ax.annotate(f\"High whisker: {whisker_high:,.0f} €\", xy=(0, whisker_high),\n",
    "            xytext=(0.1, whisker_high), color=\"green\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#plot the distributions without houses over 1M\n",
    "df_cheaper = df[(df[\"price (€)\"]) <= 1000000]\n",
    "sns.histplot(df_cheaper[\"price (€)\"], kde=True, bins=100)\n",
    "plt.gca().xaxis.set_major_locator(ticker.MaxNLocator(nbins=15))\n",
    "#plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(500_000))\n",
    "plt.xlabel(\"Price (€)\")\n",
    "plt.title('Price Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "#checking for outliers of price (quantitavely IQR and z-scores)\n",
    "#IQR\n",
    "Q1 = df[\"price (€)\"].quantile(0.25)\n",
    "Q3 = df[\"price (€)\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "#1K houses are outside of the current IQR\n",
    "outliers = df[(df[\"price (€)\"] < lower) | (df[\"price (€)\"] > upper)]\n",
    "display(outliers.head())\n",
    "print(len(outliers))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f1ca7",
   "metadata": {},
   "source": [
    "# distribution of bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many categories and how much?\n",
    "display(df[\"number_of_bedrooms\"].value_counts())\n",
    "#show 50 bedroom house\n",
    "df_fifty_bed = df[(df[\"number_of_bedrooms\"]) == 50]\n",
    "display(df_fifty_bed)\n",
    "print(\"https://immovlan.be/nl/detail/kasteel/te-koop/3840/borgloon/rbu6280\")\n",
    "#show zero bedroom house:\n",
    "df_zero_bed = df[(df[\"number_of_bedrooms\"]) == 0]\n",
    "display(df_zero_bed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d10eab",
   "metadata": {},
   "source": [
    "# distribution of living area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc8871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Living area  -> analysis : \n",
    "# visual via boxplot \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "sns.boxplot(data=df, y=\"living_area (m²)\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution (KDE + histogram)\n",
    "sns.histplot(df[\"living_area (m²)\"], kde=True, bins=100)\n",
    "plt.gca().xaxis.set_major_locator(ticker.MaxNLocator(nbins=15))\n",
    "#plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(500_000))\n",
    "plt.xlabel(\"living_area (m²)\")\n",
    "plt.title('Area Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# visual upgraded boxplot houses with living area < 500m² \n",
    "ax = sns.boxplot(data=df_cheaper, y=\"living_area (m²)\")\n",
    "\n",
    "# Extract values\n",
    "prices = df_cheaper[\"living_area (m²)\"]\n",
    "median = prices.median()\n",
    "whisker_low = np.percentile(prices, 25) - 1.5 * (np.percentile(prices, 75) - np.percentile(prices, 25))\n",
    "whisker_high = np.percentile(prices, 75) + 1.5 * (np.percentile(prices, 75) - np.percentile(prices, 25))\n",
    "\n",
    "# But real whiskers are clipped to the actual data range:\n",
    "whisker_low = prices[prices >= whisker_low].min()\n",
    "whisker_high = prices[prices <= whisker_high].max()\n",
    "\n",
    "# Annotate\n",
    "ax.annotate(f\"Median: {median:,.0f} m²\", xy=(0, median),\n",
    "            xytext=(0.1, median), color=\"black\")\n",
    "\n",
    "ax.annotate(f\"Low whisker: {whisker_low:,.0f} m²\", xy=(0, whisker_low),\n",
    "            xytext=(0.1, whisker_low), color=\"blue\")\n",
    "\n",
    "ax.annotate(f\"High whisker: {whisker_high:,.0f} m²\", xy=(0, whisker_high),\n",
    "            xytext=(0.1, whisker_high), color=\"green\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#replot the distribution without properties with areas over 500m²\n",
    "df_cheaper = df[(df[\"living_area (m²)\"]) <= 500]\n",
    "sns.histplot(df_cheaper[\"living_area (m²)\"], kde=True, bins=50)\n",
    "plt.gca().xaxis.set_major_locator(ticker.MaxNLocator(nbins=15))\n",
    "plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(50))\n",
    "plt.xlabel(\"living_area (m²)\")\n",
    "plt.title('Area Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "#checking for outliers of living area (quantitavely IQR and z-scores)\n",
    "#IQR\n",
    "Q1 = df[\"living_area (m²)\"].quantile(0.25)\n",
    "Q3 = df[\"living_area (m²)\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "#1K houses are outside of the current IQR\n",
    "outliers = df[(df[\"living_area (m²)\"] < lower) | (df[\"living_area (m²)\"] > upper)]\n",
    "display(outliers.head())\n",
    "print(len(outliers))\n",
    "\n",
    "\n",
    "#biggest living areas top 5 -> DROP the biggest one here\n",
    "df_sorted = df.sort_values(by=\"living_area (m²)\", ascending=False).head()\n",
    "display(df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bc787",
   "metadata": {},
   "source": [
    "# distribution of equiped kitchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['equiped_kitchen (yes:1, no:0)'].value_counts().plot(kind='barh')\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.title(\"Distribution equiped kitchen\")\n",
    "plt.show()\n",
    "\n",
    "#how many different values and how much are there?\n",
    "df[\"equiped_kitchen (yes:1, no:0)\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd0a4c",
   "metadata": {},
   "source": [
    "# distibrution of furnished, open fire and terrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many different values and how much are there?\n",
    "df[\"furnished (yes:1, no:0)\"].value_counts()\n",
    "\n",
    "#how many different values and how much are there?\n",
    "df[\"open_fire (yes:1, no:0)\"].value_counts()\n",
    "\n",
    "#how many different values and how much are there?\n",
    "df[\"terrace (yes:1, no:0)\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9428a",
   "metadata": {},
   "source": [
    "# distribution of terrace area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103015a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Terrace area  -> analysis : \n",
    "# visual via boxplot \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "sns.boxplot(data=df, y=\"terrace_area (m²)\")\n",
    "plt.show()\n",
    "\n",
    "# visual upgraded boxplot houses with terrace area \n",
    "ax = sns.boxplot(data=df, y=\"terrace_area (m²)\")\n",
    "\n",
    "# Extract values\n",
    "prices = df[\"terrace_area (m²)\"]\n",
    "median = prices.median()\n",
    "whisker_low = np.percentile(prices, 25) - 1.5 * (np.percentile(prices, 75) - np.percentile(prices, 25))\n",
    "whisker_high = np.percentile(prices, 75) + 1.5 * (np.percentile(prices, 75) - np.percentile(prices, 25))\n",
    "\n",
    "# But real whiskers are clipped to the actual data range:\n",
    "whisker_low = prices[prices >= whisker_low].min()\n",
    "whisker_high = prices[prices <= whisker_high].max()\n",
    "\n",
    "# Annotate\n",
    "ax.annotate(f\"Median: {median:,.0f} m²\", xy=(0, median),\n",
    "            xytext=(0.1, median), color=\"black\")\n",
    "\n",
    "\"\"\"ax.annotate(f\"Low whisker: {whisker_low:,.0f} m²\", xy=(0, whisker_low),\n",
    "            xytext=(0.1, whisker_low), color=\"blue\")\n",
    "\n",
    "ax.annotate(f\"High whisker: {whisker_high:,.0f} m²\", xy=(0, whisker_high),\n",
    "            xytext=(0.1, whisker_high), color=\"green\")\"\"\"\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution (KDE + histogram)\n",
    "sns.histplot(df[\"terrace_area (m²)\"], kde=True, bins=100)\n",
    "plt.gca().xaxis.set_major_locator(ticker.MaxNLocator(nbins=15))\n",
    "#plt.gca().xaxis.set_major_locator(ticker.MultipleLocator(500_000))\n",
    "plt.xlabel(\"terrace_area (m²)\")\n",
    "plt.title('Area Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "#checking for outliers of living area (quantitavely IQR and z-scores)\n",
    "#IQR\n",
    "Q1 = df[\"terrace_area (m²)\"].quantile(0.25)\n",
    "Q3 = df[\"terrace_area (m²)\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "#1K houses are outside of the current IQR\n",
    "outliers = df[(df[\"terrace_area (m²)\"] < lower) | (df[\"terrace_area (m²)\"] > upper)]\n",
    "display(outliers.head())\n",
    "print(len(outliers))\n",
    "\n",
    "#biggest terrace areas top 5 -> DROP the biggest one here\n",
    "df_sorted = df.sort_values(by=\"terrace_area (m²)\", ascending=False).head()\n",
    "display(df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1993e52b",
   "metadata": {},
   "source": [
    "# distribution of garden, number of facades, swimming pool and state of building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f4a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['garden (yes:1, no:0)'].value_counts().plot(kind='barh')\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.title(\"Distribution garden\")\n",
    "plt.show()\n",
    "\n",
    "#how many different values and how much are there?\n",
    "df[\"garden (yes:1, no:0)\"].value_counts()\n",
    "\n",
    "#how many different values and how much are there?\n",
    "df[\"number_facades\"].value_counts()\n",
    "\n",
    "#how many different values and how much are there?\n",
    "df[\"swimming_pool (yes:1, no:0)\"].value_counts()\n",
    "\n",
    "#how many different values and how much are there?\n",
    "display(df[\"state_of_building\"].value_counts())\n",
    "demolish = df[(df[\"state_of_building\"] == \"To demolish\")] \n",
    "display(demolish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202057b2",
   "metadata": {},
   "source": [
    "# CORRELATION ANALYSIS BETWEEN PRICE AND GDP PER CAPITA (PER PROVINCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis:\n",
    "\n",
    "\"\"\"Positive correlation (+1 for perfect correlation): the two variables change in the same direction.\n",
    "Negative correlation (-1): the two variables change in opposite directions.\n",
    "No correlation (0): there is no association or relevant relationship between the two variables.\"\"\"\n",
    "\n",
    "# Select numeric values\n",
    "numeric_df = df.select_dtypes(include=\"number\")\n",
    "\n",
    "# Correlation matrix for numeric columns\n",
    "\n",
    "corr_matrix = numeric_df.corr()\n",
    "corr_matrix['price (€)'].sort_values(ascending=False)\n",
    "\n",
    "# Visualize in a heatmap for the numeric columns (too dense)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=False)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8710ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation between two numeric variables: property price and GDP ome per capita in €:\n",
    "# Source for income per capita (gdp) per province in Belgium: Eurostat https://ec.europa.eu/eurostat/databrowser/view/tgs00003/default/table?lang=en\n",
    "\n",
    "# dictionnary gdp per capita shown per province\n",
    "\n",
    "gdp_per_province = {\"Antwerp\": 114382, \n",
    "            \"East-Flanders\": 74452, \n",
    "            \"Limburg\": 36726 , \n",
    "            \"West-Flanders\": 60931, \n",
    "            \"Flemish-Brabant\": 69558, \n",
    "            \"Liège\": 41196, \n",
    "            \"Brabant-Wallon\": 26475, \n",
    "            \"Namur\": 17623 ,\n",
    "            \"Hainaut\": 42079,\n",
    "            \"Luxembourg\": 9424,\n",
    "            \"Brussels\": 103285}\n",
    "\n",
    "# 1) Convert the dictionary to a DataFrame\n",
    "gdp_df = pd.DataFrame(list(gdp_per_province.items()), columns=[\"province\", \"GDP\"])\n",
    "\n",
    "# 2️) Display the DataFrame to check it looks right\n",
    "print(gdp_df)\n",
    "\n",
    "# 3️) Save it as a CSV file\n",
    "gdp_df.to_csv(\"gdp_per_province.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'gdp_per_province.csv' has been created!\")\n",
    "\n",
    "display(gdp_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7231c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We need to add a \"province\" column to our filtered_final_cleaned_data.csv file. \n",
    "Since we only have postal codes, we'll first need to map them to their provinces. \n",
    "We'll use a dictionary mapping postal codes to provinces.\"\"\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"filtered_final_cleaned_data.csv\")\n",
    "\n",
    "# Define postal code ranges per province\n",
    "postal_to_province = {\n",
    "    \"Antwerp\": range(2000, 3000),\n",
    "    \"East-Flanders\": range(9000, 10000),\n",
    "    \"West-Flanders\": range(8000, 9000),\n",
    "    \"Flemish-Brabant\": list(range(1500, 2000)) + list(range(3000, 3500)),\n",
    "    \"Brussels\": range(1000, 1300),\n",
    "    \"Limburg\": range(3500, 4000),\n",
    "    \"Liège\": range(4000, 5000),\n",
    "    \"Namur\": range(5000, 6000),\n",
    "    \"Hainaut\": list(range(6000, 6600)) + list(range(7000, 8000)),\n",
    "    \"Luxembourg\": range(6600, 7000),\n",
    "    \"Brabant-Wallon\": range(1300, 1500)\n",
    "}\n",
    "\n",
    "# Helper function to find province for each postal code\n",
    "def get_province(postal_code):\n",
    "    try:\n",
    "        postal_code = int(postal_code)\n",
    "        for province, codes in postal_to_province.items():\n",
    "            if postal_code in codes:\n",
    "                return province\n",
    "        return \"Unknown\"\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "# Apply the function to create a new column called \"province\" with the province names based on the postal codes.\n",
    "df[\"province\"] = df[\"postal_code\"].apply(get_province)\n",
    "\n",
    "print(df[[\"postal_code\", \"province\"]].head())\n",
    "\n",
    "# display(df.head())\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"filtered_final_cleaned_data.csv\", index=False)\n",
    "print(\"New CSV saved with 'province' column!\")\n",
    "\n",
    "# Load the new dataset with province column\n",
    "df = pd.read_csv(\"filtered_dataset_int.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea566424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average price per province \n",
    "\n",
    "avg_price = df.groupby(\"province\", as_index=False)[\"price (€)\"].mean()\n",
    "avg_price.rename(columns={\"price (€)\": \"avg_price\"}, inplace=True)\n",
    "avg_price[\"avg_price\"] = avg_price[\"avg_price\"].round(0).astype(int)\n",
    "\n",
    "display(avg_price)\n",
    "\n",
    "\n",
    "# Merge with GDP dataset\n",
    "\n",
    "gdp_df = pd.read_csv(\"gdp_per_province.csv\")\n",
    "df_merged = pd.merge(avg_price, gdp_df, on=\"province\")\n",
    "\n",
    "display(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation value between average price per province and gdp per province\n",
    "corr_value = df_merged[\"avg_price\"].corr(df_merged[\"GDP\"])\n",
    "print(f\"Correlation between average property price per province and GDP per capita per province: {corr_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correlation between gdp per capita and price in scatter plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Compute the correlation once\n",
    "corr = df_merged[\"GDP\"].corr(df_merged[\"avg_price\"])\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(df_merged[\"GDP\"], df_merged[\"avg_price\"], alpha=0.6, )  # alpha for transparency\n",
    "\n",
    "# Add province names as labels\n",
    "for i, row in df_merged.iterrows():\n",
    "    plt.text(row[\"GDP\"], row[\"avg_price\"], row[\"province\"], fontsize=9, ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel(\"GDP per capita per province (€)\")\n",
    "plt.ylabel(\"Average Property price (€)\")\n",
    "plt.title(\"Correlation between GDP per capita and Average Property Price per Province\")\n",
    "plt.grid(True,linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add correlation coefficient on the plot\n",
    "plt.text(\n",
    "    df_merged[\"GDP\"].min(),\n",
    "    df_merged[\"avg_price\"].max() * 0.95,\n",
    "    f\"Correlation: {corr:.2f}\",\n",
    "    fontsize=12,\n",
    "    color=\"red\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Add a regression (trend) line for clarity to make the relationship clearer (and not just dots), use Seaborn’s regplot:\n",
    "# the red trendline is showing the correlation, this highlights direction and strength of the correlation \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.regplot(\n",
    "    data=df_merged,\n",
    "    x=\"GDP\",\n",
    "    y=\"avg_price\",\n",
    "    scatter_kws={'alpha':0.7, 's':80},\n",
    "    line_kws={'color':'red', 'lw':2}\n",
    ")\n",
    "plt.title(\"Correlation between GDP per Capita and Property Prices per Province\", fontsize=14, weight='bold')\n",
    "\n",
    "# Add province names as labels\n",
    "for i, row in df_merged.iterrows():\n",
    "    plt.text(row[\"GDP\"], row[\"avg_price\"], row[\"province\"], fontsize=9, ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel(\"GDP per Capita (€) per province\")\n",
    "plt.ylabel(\"Average Property Price (€) per Province\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add correlation coefficient on the plot\n",
    "plt.text(\n",
    "    df_merged[\"GDP\"].min(),\n",
    "    df_merged[\"avg_price\"].max() * 0.95,\n",
    "    f\"Correlation: {corr:.2f}\",\n",
    "    fontsize=12,\n",
    "    color=\"red\"\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31700e71",
   "metadata": {},
   "source": [
    "# Correlation. Assessing the impact of real estate parameters on price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7d51be",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'filtered_final_cleaned_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m \n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spearmanr, pointbiserialr, chi2_contingency\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfiltered_final_cleaned_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m df = df.drop(columns=df.columns[:\u001b[32m2\u001b[39m]) \u001b[38;5;66;03m# Delete property_ID; locality_name\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 2. Defining column types\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repo\\immo-eliza-racoons-analysis\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repo\\immo-eliza-racoons-analysis\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repo\\immo-eliza-racoons-analysis\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repo\\immo-eliza-racoons-analysis\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Repo\\immo-eliza-racoons-analysis\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'filtered_final_cleaned_data.csv'"
     ]
    }
   ],
   "source": [
    "# 1. Import bibliothek and loading data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import spearmanr, pointbiserialr, chi2_contingency\n",
    "\n",
    "df = pd.read_csv(\"filtered_final_cleaned_data.csv\")\n",
    "df = df.drop(columns=df.columns[:2]) # Delete property_ID; locality_name\n",
    "\n",
    "# 2. Defining column types\n",
    "def detect_column_type(series, cat_threshold=15):\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        if series.nunique() == 2:\n",
    "            return \"binary\"\n",
    "        else:\n",
    "            return \"numerical\"\n",
    "    else:\n",
    "        if series.nunique() == 2:\n",
    "            return \"binary\"\n",
    "        elif series.nunique() <= cat_threshold:\n",
    "            return \"categorical\"\n",
    "        else:\n",
    "            return \"categorical\"\n",
    "\n",
    "column_types = {col: detect_column_type(df[col]) for col in df.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5735824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Functions for calculating correlation\n",
    "\n",
    "# Convert a 2-class categorical series to 0/1\n",
    "def encode_binary(series):\n",
    "\n",
    "    if series.nunique() != 2:\n",
    "        return series\n",
    "    classes = list(series.unique())\n",
    "    mapping = {classes[0]: 0, classes[1]: 1}\n",
    "    return series.map(mapping)\n",
    "\n",
    "# Eta_squared: Numerical vs Categorical\n",
    "def eta_squared(df, numerical, categorical):\n",
    "    groups = df.groupby(categorical)[numerical]\n",
    "    ss_between = sum([len(g) * (g.mean() - df[numerical].mean())**2 for name, g in groups])\n",
    "    ss_total = sum((df[numerical] - df[numerical].mean())**2)\n",
    "    return ss_between / ss_total if ss_total != 0 else 0\n",
    "\n",
    "# Spearman: Numerical vs Numerical\n",
    "def safe_spearman(a, b):\n",
    "    a_num = pd.to_numeric(a, errors='coerce')\n",
    "    b_num = pd.to_numeric(b, errors='coerce')\n",
    "    mask = a_num.notna() & b_num.notna()\n",
    "    if mask.sum() < 3:\n",
    "        return np.nan\n",
    "    val, _ = spearmanr(a_num[mask], b_num[mask])\n",
    "    return val\n",
    "\n",
    "# Point-Biserial: Binary vs Numerical\n",
    "def safe_pointbiserial(numeric, binary):\n",
    "    numeric = pd.to_numeric(numeric, errors='coerce')\n",
    "    binary = pd.to_numeric(binary, errors='coerce')\n",
    "    mask = numeric.notna() & binary.notna()\n",
    "    if mask.sum() < 3:\n",
    "        return np.nan\n",
    "    try:\n",
    "        val, _ = pointbiserialr(numeric[mask], binary[mask])\n",
    "        return val\n",
    "    except Exception:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Construction of a “correlation vector” with \"price (€)\"\n",
    "def correlation_value(x, y, type_x, type_y):\n",
    "    try:\n",
    "        # numerical-numerical\n",
    "        if type_x == \"numerical\" and type_y == \"numerical\":\n",
    "            return safe_spearman(x, y)\n",
    "\n",
    "        # numerical-binary\n",
    "        if type_x == \"binary\" and type_y == \"numerical\":\n",
    "            return safe_pointbiserial(encode_binary(x), y)\n",
    "        if type_x == \"numerical\" and type_y == \"binary\":\n",
    "            return safe_pointbiserial(x, encode_binary(y))\n",
    "\n",
    "        # numerical-categorical\n",
    "        if type_x == \"numerical\" and type_y == \"categorical\":\n",
    "            return eta_squared(df, x.name, y.name)\n",
    "\n",
    "        if type_x == \"categorical\" and type_y == \"numerical\":\n",
    "            return eta_squared(df, y.name, x.name)\n",
    "\n",
    "        # binary-binary\n",
    "        if type_x == \"binary\" and type_y == \"binary\":\n",
    "            return phi_coefficient(x, y)\n",
    "\n",
    "        # categorical-categorical\n",
    "        if type_x == \"categorical\" and type_y == \"categorical\":\n",
    "            return cramers_v(x, y)\n",
    "\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "columns = df.columns\n",
    "\n",
    "target = \"price (€)\"           # field to compare with\n",
    "corr_vector = {}               # Let's add the correlations here\n",
    "\n",
    "for col in df.columns:\n",
    "    if col == target:\n",
    "        continue\n",
    "    t1 = column_types[col]\n",
    "    t2 = column_types[target]\n",
    "    corr_vector[col] = correlation_value(df[col], df[target], t1, t2)\n",
    "\n",
    "corr_vector = pd.Series(corr_vector).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nMixed correlation vector with target:\", target)\n",
    "# print(corr_vector)\n",
    "print(corr_vector.abs().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualization of a mixed matrix\n",
    "plt.figure(figsize=(6, 12))\n",
    "\n",
    "# seaborn heatmap expects a 2D matrix → convert Series to DataFrame\n",
    "corr_df = corr_vector.to_frame(name=\"correlation\")\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr_df,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    cbar=True,\n",
    "    cbar_kws={\"orientation\": \"horizontal\"}\n",
    ")\n",
    "\n",
    "plt.title(f\"Correlation with {target}\", pad=50)\n",
    "\n",
    "# Get existing colorbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "\n",
    "# Move ticks to the top of colorbar\n",
    "cbar.ax.xaxis.set_label_position('top')\n",
    "cbar.ax.xaxis.tick_top()\n",
    "\n",
    "# Reposition colorbar under the title\n",
    "bbox = ax.get_position()\n",
    "cbar.ax.set_position([bbox.x0, bbox.y1 + 0.03, bbox.width, 0.02])\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Features\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # leave space for colorbar and title\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Top 5 Strongest Relationships\n",
    "top5 = corr_vector.abs().sort_values(ascending=False).head(5)\n",
    "top5 = corr_vector.loc[top5.index]\n",
    "top5\n",
    "\n",
    "# 7. Visualization of the TOP-5 strongest connections\n",
    "top5 = corr_vector.abs().sort_values(ascending=False).head(5)\n",
    "top5 = corr_vector.loc[top5.index]   # restore ± sign\n",
    "\n",
    "print(\"\\nTOP-5 strongest correlations with price (€):\")\n",
    "print(top5)\n",
    "\n",
    "# --- Visualization of TOP-5 as individual plots ---\n",
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "for i, feature in enumerate(top5.index, 1):\n",
    "    plt.subplot(5, 1, i)\n",
    "\n",
    "    ftype = column_types[feature]\n",
    "\n",
    "    # Numerical vs Numerical → SCATTERPLOT + TREND LINE\n",
    "    if ftype == \"numerical\":\n",
    "        # scatter\n",
    "        sns.scatterplot(data=df, x=feature, y=target, alpha=0.5)\n",
    "        \n",
    "        # ---- trend line ----\n",
    "        # drop NaN\n",
    "        x = df[feature].astype(float)\n",
    "        y = df[target].astype(float)\n",
    "        mask = x.notna() & y.notna()\n",
    "\n",
    "        if mask.sum() > 2:\n",
    "            # linear regression\n",
    "            slope, intercept = np.polyfit(x[mask], y[mask], 1)\n",
    "            x_line = np.linspace(x.min(), x.max(), 100)\n",
    "            y_line = slope * x_line + intercept\n",
    "\n",
    "            plt.plot(x_line, y_line, linewidth=2)\n",
    "\n",
    "        plt.title(f\"{feature} vs {target} (numerical → scatter + trend line)\")\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(target)\n",
    "\n",
    "    # Binary vs Numerical → BOXPLOT (trend line NOT applicable)\n",
    "    elif ftype == \"binary\":\n",
    "        sns.boxplot(data=df, x=feature, y=target)\n",
    "        plt.title(f\"{feature} vs {target} (binary → boxplot)\")\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(target)\n",
    "\n",
    "    # Categorical vs Numerical → BOXPLOT (trend line NOT applicable)\n",
    "    elif ftype == \"categorical\":\n",
    "        # Если категорий слишком много — показывать только top-10 самых частых\n",
    "        if df[feature].nunique() > 10:\n",
    "            top_categories = df[feature].value_counts().head(10).index\n",
    "            sub_df = df[df[feature].isin(top_categories)]\n",
    "            sns.boxplot(data=sub_df, x=feature, y=target)\n",
    "            plt.title(f\"{feature} vs {target} (categorical, top-10 categories)\")\n",
    "        else:\n",
    "            sns.boxplot(data=df, x=feature, y=target)\n",
    "            plt.title(f\"{feature} vs {target} (categorical → boxplot)\")\n",
    "\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(target)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ab6c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Now do the same, but for the median price per province instead of the average price\"\"\"\n",
    "\n",
    "# Calculate the median price per province \n",
    "\n",
    "median_price = df.groupby(\"province\", as_index=False)[\"price (€)\"].median()\n",
    "median_price.rename(columns={\"price (€)\": \"median_price\"}, inplace=True)\n",
    "median_price[\"median_price\"] = median_price[\"median_price\"].round(0).astype(int)\n",
    "\n",
    "display(median_price)\n",
    "\n",
    "# Merge with GDP dataset\n",
    "\n",
    "gdp_df = pd.read_csv(\"gdp_per_province.csv\")\n",
    "df_merged = pd.merge(median_price, gdp_df, on=\"province\")\n",
    "\n",
    "display(df_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation value between median price per province and gdp per province\n",
    "corr_value = df_merged[\"median_price\"].corr(df_merged[\"GDP\"])\n",
    "print(f\"Correlation between median property price per province and GDP per capita per province: {corr_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the correlation between gdp per capita and median price in scatter plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Compute the correlation once\n",
    "corr = df_merged[\"GDP\"].corr(df_merged[\"median_price\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(df_merged[\"GDP\"], df_merged[\"median_price\"], alpha=0.6, )  # alpha for transparency\n",
    "\n",
    "# Add province names as labels\n",
    "for i, row in df_merged.iterrows():\n",
    "    plt.text(row[\"GDP\"], row[\"median_price\"], row[\"province\"], fontsize=9, ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel(\"GDP per capita per province (€)\")\n",
    "plt.ylabel(\"Median Property price (€)\")\n",
    "plt.title(\"Correlation between GDP per capita and Median Property Price per Province\")\n",
    "plt.grid(True,linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add correlation coefficient on the plot\n",
    "plt.text(\n",
    "    df_merged[\"GDP\"].min(),\n",
    "    df_merged[\"median_price\"].max() * 0.95,\n",
    "    f\"Correlation: {corr:.2f}\",\n",
    "    fontsize=12,\n",
    "    color=\"red\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Add a regression (trend) line for clarity to make the relationship clearer (and not just dots), use Seaborn’s regplot:\n",
    "# the red trendline is showing the correlation, this highlights direction and strength of the correlation \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "sns.regplot(\n",
    "    data=df_merged,\n",
    "    x=\"GDP\",\n",
    "    y=\"median_price\",\n",
    "    scatter_kws={'alpha':0.7, 's':80},\n",
    "    line_kws={'color':'red', 'lw':2}\n",
    ")\n",
    "plt.title(\"Correlation between GDP per Capita and Median Property Prices per Province\", fontsize=14, weight='bold')\n",
    "\n",
    "# Add province names as labels\n",
    "for i, row in df_merged.iterrows():\n",
    "    plt.text(row[\"GDP\"], row[\"median_price\"], row[\"province\"], fontsize=9, ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel(\"GDP per Capita (€) per province\")\n",
    "plt.ylabel(\"Median Property Price (€) per Province\")\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add correlation coefficient on the plot\n",
    "plt.text(\n",
    "    df_merged[\"GDP\"].min(),\n",
    "    df_merged[\"median_price\"].max() * 0.95,\n",
    "    f\"Correlation: {corr:.2f}\",\n",
    "    fontsize=12,\n",
    "    color=\"red\"\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a91d11",
   "metadata": {},
   "source": [
    "Conclusion for correlation between gdp per capita and median property prices: \n",
    "- there is a positive correlation (correlation value 0,48) between socioeconomic indicators like gdp per capita and property prices. \n",
    "- 0.48 = moderate positive correlation => It is meaningful, but not strong.\n",
    "-The variables move somewhat together, but many exceptions exist.\n",
    "- Our result of 0.48 means that there is a real connection between wealth of a province and housing prices.\n",
    "But GDP per capita alone cannot predict housing prices accurately.\n",
    "- How to interpret it properly:\n",
    "A correlation of 0.48 implies:\n",
    "GDP per capita explains around 23% of the variation in property prices\n",
    "(because correlation² = 0.48² ≈ 0.23 → “explained variance”).\n",
    "So:\n",
    "23% of the differences in property prices across provinces\n",
    "could be associated with GDP per capita.\n",
    "The other 77% is explained by other factors such as supply/demand, population density, region attractiveness, nearby cities, salary distribution, housing supply, etc.\n",
    "So GDP per capita has influence — but it’s not the only important factor.\n",
    "\n",
    "Are the values (0.48 and 0.50) realistic? Yes.\n",
    "In Belgium:\n",
    "Property prices correlate with wealth, but not perfectly.\n",
    "Brussels is high GDP but also has many cheap apartments.\n",
    "Wallonia has low GDP but also some pockets of expensive rural houses.\n",
    "Flanders has higher GDP but also large variation inside provinces.\n",
    "Typical correlations found in academic or market studies range from 0.3 to 0.7, depending heavily on the variable definition.\n",
    "\n",
    "A higher correlation is definitely possible — but only under certain conditions, like:\n",
    "A different data source (more complete, more luxury listings)\n",
    "Prices aggregated differently (per type of property, per year, per municipality)\n",
    "Cleaned outliers differently (e.g., removing €30k listings that distort the median)\n",
    "Aggregated over a different time window\n",
    "Used a dataset with more balanced counts per province"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa650a",
   "metadata": {},
   "source": [
    "# RANKINGS: What are the least/most expensive provinces and municipalities in Belgium/Wallonia/Flanders? (in terms of price per m², average price, and median price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34467123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" - Average price per province and per municipality  => draw conclusion in terms of least/most expensive\n",
    "    - Median price per province and per municipality => draw conclusion in terms of least/most expensive\n",
    "    - Price per m² per province and municipality => draw conclusion in terms of least/most expensive\"\"\"\n",
    "\n",
    "# 1) Create a \"price per m²” column (we need this for all ranking questions)\n",
    "# Take the living area in m² to make the calculation (most common - later we can add terrace area annd garden area)\n",
    "\n",
    "df = pd.read_csv(\"filtered_final_cleaned_data.csv\")\n",
    "\n",
    "df['price_per_m2'] = df['price (€)'] / df['living_area (m²)']\n",
    "df['price_per_m2'] = df['price_per_m2'].round(0)\n",
    "\n",
    "\n",
    "df.to_csv(\"filtered_final_cleaned_data.csv\", index=False)\n",
    "\n",
    "df[['price (€)', 'living_area (m²)', 'price_per_m2']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b7f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 2) Calculate stats per province: Average&median price and average&median price per m²:\n",
    "This answers:\n",
    "Most/least expensive province by average price\n",
    "Most/least expensive province by median price\n",
    "Most/least expensive province by price per m²\"\"\"\n",
    "\n",
    "province_stats = df.groupby('province').agg({\n",
    "    'price (€)': ['mean', 'median'],\n",
    "    'price_per_m2': ['mean', 'median']\n",
    "})\n",
    "\n",
    "province_stats = province_stats.round(0).astype(\"Int64\")              # Round the results to integers\n",
    "\n",
    "province_stats.sort_values(('price (€)','mean'), ascending=False)     # Most expensive avg price\n",
    "province_stats.sort_values(('price (€)','mean'), ascending=True)      # Least expensive avg price\n",
    "\n",
    "province_stats.sort_values(('price (€)','median'), ascending=False)     # Most expensive median price\n",
    "province_stats.sort_values(('price (€)','median'), ascending=True)      # Least expensive median price\n",
    "\n",
    "province_stats.sort_values(('price_per_m2','mean'), ascending=False)\n",
    "province_stats.sort_values(('price_per_m2','mean'), ascending=True)\n",
    "\n",
    "display(province_stats.sort_values(('price (€)','mean'), ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"3) Calculate stats per municipality: same approach as for the stats per province above.\n",
    "This answers:\n",
    "Most/least expensive municipality (avg price)\n",
    "Most/least expensive municipality (median price)\n",
    "Most/least expensive municipality (price/m²)\"\"\"\n",
    "\n",
    "\n",
    "# Remove leftover municipality columns from earlier merges\n",
    "df = df.drop(columns=[col for col in df.columns if col.startswith(\"municipality\")],\n",
    "             errors=\"ignore\")\n",
    "\n",
    "# Load postal codes from separate csv file with official postal codes and municipality names\n",
    "\n",
    "postal_codes = pd.read_csv(\n",
    "    \"postal-codes-belgium.csv\",\n",
    "    sep=\";\",\n",
    "    engine=\"python\",\n",
    "    on_bad_lines=\"skip\",\n",
    "    usecols=[\"Postal Code\", \"Municipality name (Dutch)\", \"Municipality name (French)\"])\n",
    "\n",
    "postal_codes[\"municipality\"] = (\n",
    "    postal_codes[\"Municipality name (Dutch)\"].fillna(postal_codes[\"Municipality name (French)\"])\n",
    ")\n",
    "\n",
    "\n",
    "# Merge the municipality column into your property dataset\n",
    "df = df.merge(\n",
    "    postal_codes[[\"Postal Code\", \"municipality\"]],\n",
    "    left_on=\"postal_code\",\n",
    "    right_on=\"Postal Code\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Drop the duplicate column \n",
    "df = df.drop(columns=[\"Postal Code\"])\n",
    "\n",
    "df.to_csv(\"filtered_final_cleaned_data.csv\", index=False)\n",
    "\n",
    "# Count listings per municipality\n",
    "counts = df['municipality'].value_counts()\n",
    "\n",
    "# Keep only municipalities with >= 10 listings\n",
    "valid_municipalities = counts[counts >= 10].index\n",
    "\n",
    "# Filter your main df\n",
    "df_filtered = df[df['municipality'].isin(valid_municipalities)]\n",
    "\n",
    "\n",
    "# Stats per municipality \n",
    "\n",
    "municipality_stats = df_filtered.groupby('municipality').agg({\n",
    "    'price (€)': ['mean', 'median'],\n",
    "    'price_per_m2': ['mean', 'median']\n",
    "})\n",
    "municipality_stats = municipality_stats.round(0).astype(\"Int64\")            # Round the results to integers\n",
    "\n",
    "\n",
    "municipality_stats.sort_values(('price (€)','mean'), ascending=False)       # Top 10 expensive avg\n",
    "municipality_stats.sort_values(('price (€)','mean'), ascending=True)        # Top 10 cheap avg\n",
    "\n",
    "municipality_stats.sort_values(('price (€)','median'), ascending=False)     # Top 10 expensive median\n",
    "municipality_stats.sort_values(('price (€)','median'), ascending=True)      # Top 10 cheap median\n",
    "\n",
    "municipality_stats.sort_values(('price_per_m2','mean'), ascending=False)\n",
    "municipality_stats.sort_values(('price_per_m2','mean'), ascending=True)\n",
    "\n",
    "display(municipality_stats.sort_values(('price (€)','mean'), ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23124f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"4) Filter by region (Wallonia vs Flanders vs Brussels)\"\"\"\n",
    "\n",
    "# Create a region column one time\n",
    "\n",
    "df = pd.read_csv(\"filtered_final_cleaned_data.csv\")\n",
    "\n",
    "def get_region(province):\n",
    "    flanders = ['Antwerp', 'Limburg', 'East-Flanders', 'West-Flanders', 'Flemish-Brabant']\n",
    "    wallonia = ['Hainaut', 'Liège', 'Luxembourg', 'Namur', 'Brabant-Wallon']\n",
    "    brussels = ['Brussels']\n",
    "\n",
    "    if province in flanders:\n",
    "        return 'Flanders'\n",
    "    if province in wallonia:\n",
    "        return 'Wallonia'\n",
    "    return 'Brussels'\n",
    "\n",
    "df['region'] = df['province'].apply(get_region)\n",
    "\n",
    "df.to_csv(\"filtered_final_cleaned_data.csv\", index=False)\n",
    "\n",
    "# Stats per region\n",
    "\n",
    "region_stats = df.groupby('region').agg({\n",
    "    'price (€)': ['mean', 'median'],\n",
    "    'price_per_m2': ['mean', 'median']\n",
    "})\n",
    "\n",
    "region_stats = region_stats.round(0).astype(\"Int64\")  \n",
    "\n",
    "display(region_stats)\n",
    "\n",
    "\"\"\"Conclusion: Brussels is the region with the highest average prices and highest average price per m2 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f87bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisations of average prices and prices per m2 per province and per municipality\n",
    "\n",
    "# Most Expensive Provinces Ranking (Average Price)\n",
    "\n",
    "top10_expensive_provinces = (\n",
    "    df.groupby('province')['price (€)']\n",
    "      .mean()\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(top10_expensive_provinces.index, top10_expensive_provinces.values)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Most Expensive Provinces Ranking (Average Price)\")\n",
    "plt.xlabel(\"Average Price (€)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top Ten Most Expansive Municipalities (Average Price)\n",
    "\n",
    "top10_expensive_municipalities = (\n",
    "    df_filtered.groupby('municipality')['price (€)']\n",
    "      .mean()\n",
    "      .sort_values(ascending=False)\n",
    "      .head(10)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(top10_expensive_municipalities.index, top10_expensive_municipalities.values)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 10 Most Expensive Municipalities (Average Price)\")\n",
    "plt.xlabel(\"Average Price (€)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Median Price per Province\n",
    "\n",
    "median_province = (\n",
    "    df.groupby('province')['price (€)']\n",
    "      .median()\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(median_province.index, median_province.values)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Median Price per Province\")\n",
    "plt.xlabel(\"Median Price (€)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top 10 most expensive median price per Municipality\n",
    "\n",
    "\n",
    "top10_expensive_municipalities_median = (\n",
    "    df_filtered.groupby('municipality')['price (€)']\n",
    "      .median()\n",
    "      .sort_values(ascending=False)\n",
    "      .head(10)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.barh(top10_expensive_municipalities_median.index, top10_expensive_municipalities_median.values)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 10 Most Expensive Municipalities (Median Price)\")\n",
    "plt.xlabel(\"Median Price (€)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Price per m² per Province (Average)\n",
    "\n",
    "df['price_per_m2'] = df['price (€)'] / df['living_area (m²)']\n",
    "\n",
    "avg_ppm_province = (\n",
    "    df.groupby('province')['price_per_m2']\n",
    "      .mean()\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(avg_ppm_province.index, avg_ppm_province.values)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Average Price per m² per Province\")\n",
    "plt.xlabel(\"Price per m² (€)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Price per m² per Municipality\n",
    "\n",
    "top10_ppm = (\n",
    "    df_filtered.groupby('municipality')['price_per_m2']\n",
    "      .mean()\n",
    "      .sort_values(ascending=False)\n",
    "      .head(10)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(top10_ppm.index, top10_ppm.values)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 10 Most Expensive Municipalities (Price per m²)\")\n",
    "plt.xlabel(\"Price per m² (€)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb14fc8",
   "metadata": {},
   "source": [
    "# Correlation Analysis and price comparison between different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "def clean_and_load():\n",
    "\n",
    "    df = pd.read_csv(\"filtered_final_cleaned_data.csv\")\n",
    "\n",
    "    # converting float to int\n",
    "    df = df.apply(lambda x: x.astype(\"Int64\") if x.dtype == float and (x.dropna() % 1 == 0).all() else x)\n",
    "\n",
    "    # converting objects to strings\n",
    "    df['property_ID'] = df['property_ID'].astype('string')\n",
    "    df['locality_name'] = df['locality_name'].astype('string')\n",
    "    df['type'] = df['type'].astype('category')\n",
    "    df['subtype'] = df['subtype'].astype('category')\n",
    "    df['state_of_building'] = df['state_of_building'].astype('category')\n",
    "    df['postal_code'] = df['postal_code'].astype('category')\n",
    "    \n",
    "    # removing properties that do not have the price\n",
    "    df = df.dropna(subset=[\"price (€)\"])\n",
    "    #display(df.dtypes)\n",
    "    df.to_csv(\"cleaned_data_int.csv\", index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = clean_and_load()\n",
    "\n",
    "# --- Display results in notebook ---\n",
    "display(df.dtypes)   # Shows column types         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd65e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_postal_code():\n",
    "\n",
    "    df = clean_and_load()\n",
    "    \n",
    "    # ANOVA: treats postal_code as categorical\n",
    "    model = ols('Q(\"price (€)\") ~ C(postal_code)', data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model)\n",
    "    print(anova_table)  \n",
    "\n",
    "    # Group by location to compute median price and count of listings\n",
    "    median_price_by_location = df.groupby(\"postal_code\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_location[\"median_price\"] = median_price_by_location[\"median_price\"].round(2)\n",
    "\n",
    "    # scatter plot\n",
    "    fig = px.scatter(median_price_by_location, x=\"postal_code\", y=\"median_price\", size=\"num_listings\", title=\"Price variation based on Postal Code\", labels={\"postal_code\": \"Postal Code\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.show()\n",
    "\n",
    "    # print(median_price_by_location.head())\n",
    "    return df\n",
    "\n",
    "df = price_corr_postal_code()\n",
    "\n",
    "# The F-statistic is 6.579, and p-value is essentially zero.\n",
    "# This means there is a statistically significant difference in price across postal codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952fc6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_number_of_bedrooms():\n",
    "    df = clean_and_load()\n",
    "\n",
    "    # Compute correlation between number of bedrooms and property price\n",
    "    corr = df[\"number_of_bedrooms\"].corr(df[\"price (€)\"])\n",
    "    print(f\"Correlation between number of bedrooms and price: {corr:.2f}\")\n",
    "\n",
    "    # Group by number of bedrooms to compute median price and count of listings\n",
    "    median_price_by_bedrooms = df.groupby(\"number_of_bedrooms\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_bedrooms[\"median_price\"] = median_price_by_bedrooms[\"median_price\"].round(2)\n",
    "\n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_bedrooms, x=\"number_of_bedrooms\", y=\"median_price\", text=\"median_price\", title=\"Price variation based on number of bedrooms\", labels={\"number_of_bedrooms\": \"Number of Bedrooms\", \"median_price\": \"Median Price (€)\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_bedrooms[\"median_price\"].max()*1.1])\n",
    "    fig.update_xaxes(dtick=1)\n",
    "    fig.show()\n",
    "\n",
    "    # print(median_price_by_bedrooms.head())\n",
    "    return df\n",
    "\n",
    "df = price_corr_number_of_bedrooms()\n",
    "# print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_living_area():\n",
    "    df = clean_and_load()\n",
    "\n",
    "    # Compute correlation between living area and property price\n",
    "    corr = df[\"living_area (m²)\"].corr(df[\"price (€)\"])\n",
    "    print(f\"Correlation between living area and price: {corr:.2f}\")\n",
    "\n",
    "    # Group by living area to compute median price and count of listings\n",
    "    median_price_by_living_area = df.groupby(\"living_area (m²)\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_living_area[\"median_price\"] = median_price_by_living_area[\"median_price\"].round(2)\n",
    "\n",
    "    # scatter plot\n",
    "    fig = px.scatter(median_price_by_living_area, x=\"living_area (m²)\", y=\"median_price\", size=\"num_listings\", trendline = \"ols\", title=\"Price variation based on living area (m²)\", labels={\"living_area (m²)\": \"Living area (m²)\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.show()\n",
    "\n",
    "    print(median_price_by_living_area.head())\n",
    "    return df\n",
    "\n",
    "df = price_corr_living_area()\n",
    "# print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c06dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_swimming_pool():\n",
    "    df = clean_and_load()\n",
    "\n",
    "    # Compute correlation between presence of swimming pool (yes:1, no:0) and property price\n",
    "    corr = df[\"swimming_pool (yes:1, no:0)\"].corr(df[\"price (€)\"])\n",
    "    print(f\"Correlation between swimming pool and price: {corr:.2f}\")\n",
    "    df[\"swimming_pool_str\"] = df[\"swimming_pool (yes:1, no:0)\"].map({0: \"No\", 1: \"Yes\"})\n",
    "\n",
    "    \"\"\" OTUCOME --> Houses with a swimming pool tend to be slightly more expensive on average, but the effect is not strong.\"\"\"\n",
    "\n",
    "    # Group by swimming pool presence to compute median price and count of listings\n",
    "    median_price_by_swimming_pool = df.groupby(\"swimming_pool_str\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_swimming_pool[\"median_price\"] = median_price_by_swimming_pool[\"median_price\"].round(2)\n",
    "    \n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_swimming_pool, x=\"swimming_pool_str\", y=\"median_price\", color=\"num_listings\", text=\"median_price\", title=\"Price variation based on swimming pool\", labels={\"swimming_pool_str\": \"Swimming Pool\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_swimming_pool[\"median_price\"].max()*1.1])\n",
    "    fig.show()\n",
    "\n",
    "    print(median_price_by_swimming_pool.head())\n",
    "    return df\n",
    "\n",
    "df = price_corr_swimming_pool()\n",
    "# print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33edc2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_garden():\n",
    "    df = clean_and_load()\n",
    "\n",
    "    # Compute correlation between presence of garden (yes:1, no:0) and property price\n",
    "    corr = df[\"garden (yes:1, no:0)\"].corr(df[\"price (€)\"])\n",
    "    print(f\"Correlation between garden and price: {corr:.2f}\")\n",
    "    df[\"garden_str\"] = df[\"garden (yes:1, no:0)\"].map({0: \"No\", 1: \"Yes\"})\n",
    "\n",
    "    \"\"\" OUTCOME: Houses with gardens tend to be slightly more expensive on average, but the effect is not strong.\"\"\"\n",
    "    \n",
    "    # Group by garden presence to compute median price and count of listings\n",
    "    median_price_by_garden = df.groupby(\"garden_str\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_garden[\"median_price\"] = median_price_by_garden[\"median_price\"].round(2)\n",
    "\n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_garden, x=\"garden_str\", y=\"median_price\", color=\"num_listings\", text=\"median_price\", title=\"Price Variation by Garden Presence\", labels={\"garden_str\": \"Garden\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_garden[\"median_price\"].max()*1.1])\n",
    "    fig.show()\n",
    "\n",
    "    print(median_price_by_garden.head())\n",
    "    return df\n",
    "\n",
    "df = price_corr_garden()\n",
    "# print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_number_of_facades():\n",
    "    df = clean_and_load()\n",
    "\n",
    "    # Compute correlation between number of facades and property price\n",
    "    corr = df[\"number_facades\"].corr(df[\"price (€)\"])\n",
    "    print(f\"Correlation between number of facades and price: {corr:.2f}\")\n",
    "    \n",
    "    # Group by number of bedrooms to compute median price and count of listings\n",
    "    median_price_by_facades = df.groupby(\"number_facades\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_facades[\"median_price\"] = median_price_by_facades[\"median_price\"].round(2)\n",
    "\n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_facades, x=\"number_facades\", y=\"median_price\", text=\"median_price\", title=\"Price variation based on number facades\", labels={\"number_facades\": \"Number Facades\", \"median_price\": \"Median Price (€)\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_facades[\"median_price\"].max()*1.1])\n",
    "    fig.update_xaxes(dtick=1)\n",
    "    fig.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = price_corr_number_of_facades()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cd2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_terrace_area():\n",
    "    df = clean_and_load()\n",
    "\n",
    "    # Compute correlation between terrace area and property price\n",
    "    corr = df[\"terrace_area (m²)\"].corr(df[\"price (€)\"])\n",
    "    print(f\"Correlation between terrace area and price: {corr:.2f}\")\n",
    "\n",
    "    # Group by living area to compute median price and count of listings\n",
    "    median_price_by_terrace_area = df.groupby(\"terrace_area (m²)\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_terrace_area[\"median_price\"] = median_price_by_terrace_area[\"median_price\"].round(2)\n",
    "\n",
    "    # scatter plot\n",
    "    fig = px.scatter(median_price_by_terrace_area, x=\"terrace_area (m²)\", y=\"median_price\", trendline = \"ols\", size=\"num_listings\", title=\"Price variation based on terrace area\", labels={\"terrace_area (m²)\": \"Terrace area (m²)\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = price_corr_terrace_area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f8d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_terrace():\n",
    "    df = clean_and_load()\n",
    "\n",
    "    # Compute correlation between presence of terrace (yes:1, no:0) and property price\n",
    "    corr = df[\"terrace (yes:1, no:0)\"].corr(df[\"price (€)\"])\n",
    "    print(f\"Correlation between terrace and price: {corr:.2f}\")\n",
    "    df[\"terrace_str\"] = df[\"terrace (yes:1, no:0)\"].map({0: \"No\", 1: \"Yes\"})\n",
    "\n",
    "    \"\"\" OUTCOME: Houses with terraces tend to be slightly more expensive on average, but the effect is not strong.\"\"\"\n",
    "\n",
    "    # Group by terrace presence to compute median price and count of listings\n",
    "    median_price_by_terrace = df.groupby(\"terrace_str\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_terrace[\"median_price\"] = median_price_by_terrace[\"median_price\"].round(2)\n",
    "\n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_terrace, x=\"terrace_str\", y=\"median_price\", color=\"num_listings\", text=\"median_price\", title=\"Price Variation by Terrace Presence\", labels={\"terrace_str\": \"Terrace\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_terrace[\"median_price\"].max()*1.1])\n",
    "    fig.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = price_corr_terrace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46922bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_open_fire():\n",
    "    df = clean_and_load()\n",
    "\n",
    "    # Compute correlation between presence of open fire (yes:1, no:0) and property price\n",
    "    corr = df[\"open_fire (yes:1, no:0)\"].corr(df[\"price (€)\"])\n",
    "    print(f\"Correlation between open fire and price: {corr:.2f}\")\n",
    "    df[\"open_fire_str\"] = df[\"open_fire (yes:1, no:0)\"].map({0: \"No\", 1: \"Yes\"})\n",
    "\n",
    "    \"\"\" OUTCOME: Houses with open fire tend to be slightly more expensive on average, but the effect is not strong.\"\"\"\n",
    "\n",
    "    # Group by terrace presence to compute median price and count of listings\n",
    "    median_price_by_open_fire = df.groupby(\"open_fire_str\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_open_fire[\"median_price\"] = median_price_by_open_fire[\"median_price\"].round(2)\n",
    "\n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_open_fire, x=\"open_fire_str\", y=\"median_price\", color=\"num_listings\", text=\"median_price\", title=\"Price Variation by open fire\", labels={\"open_fire_str\": \"Open Fire\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_open_fire[\"median_price\"].max()*1.1])\n",
    "    fig.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = price_corr_open_fire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e3b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_furnished():\n",
    "    df = clean_and_load()\n",
    "\n",
    "    # Compute correlation between furnished property and property price\n",
    "    corr = df[\"furnished (yes:1, no:0)\"].corr(df[\"price (€)\"])\n",
    "    print(f\"Correlation between furnished property and price: {corr:.2f}\")\n",
    "    df[\"furnished_str\"] = df[\"furnished (yes:1, no:0)\"].map({0: \"No\", 1: \"Yes\"})\n",
    "\n",
    "    \"\"\" OUTCOME: A correlation that is close to zero suggests that — statistically —\n",
    "    whether a property is furnished or not does not influence the price in the dataset.\"\"\"\n",
    "\n",
    "    # Group by terrace presence to compute median price and count of listings\n",
    "    median_price_by_furnished = df.groupby(\"furnished_str\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_furnished[\"median_price\"] = median_price_by_furnished[\"median_price\"].round(2)\n",
    "\n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_furnished, x=\"furnished_str\", y=\"median_price\", color=\"num_listings\", text=\"median_price\", title=\"Price Variation depending if the property is furnished\", labels={\"furnished_str\": \"Furnished\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_furnished[\"median_price\"].max()*1.1])\n",
    "    fig.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = price_corr_furnished()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_equipped_kitchen():\n",
    "    df = clean_and_load()\n",
    "\n",
    "    # Compute correlation between equipped kitchen and property price\n",
    "    corr = df[\"equiped_kitchen (yes:1, no:0)\"].corr(df[\"price (€)\"])\n",
    "    print(f\"Correlation between equipped kitchen and price: {corr:.2f}\")\n",
    "    df[\"equipped_kitchen_str\"] = df[\"equiped_kitchen (yes:1, no:0)\"].map({0: \"No\", 1: \"Yes\"})\n",
    "\n",
    "    \"\"\" OUTCOME: A correlation that is close to zero suggests that — statistically — \n",
    "    whether a property has an equipped kitchen or not does not influence the price in the dataset\"\"\"\n",
    "\n",
    "    # Group by terrace presence to compute median price and count of listings\n",
    "    median_price_by_equipped_kitchen = df.groupby(\"equipped_kitchen_str\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_equipped_kitchen[\"median_price\"] = median_price_by_equipped_kitchen[\"median_price\"].round(2)\n",
    "\n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_equipped_kitchen, x=\"equipped_kitchen_str\", y=\"median_price\", color=\"num_listings\", text=\"median_price\", title=\"Price Variation depending if the property has equipped kitchen\", labels={\"equipped_kitchen_str\": \"Equipped Kitchen\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_equipped_kitchen[\"median_price\"].max()*1.1])\n",
    "    fig.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "df = price_corr_furnished()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_state_of_building():\n",
    "    df = clean_and_load()\n",
    "    \n",
    "    # ANOVA: treats state of building as categorical\n",
    "    model = ols('Q(\"price (€)\") ~ C(state_of_building)', data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model)\n",
    "    print(anova_table)\n",
    "\n",
    "    \"\"\" The ANOVA shows that the state of the building has a highly significant effect on property price (p ≈ 2.3e-112). \n",
    "    However, the effect size is modest, meaning building condition explains only a small portion of the overall price variation.\"\"\"  \n",
    "\n",
    "    # Group by location to compute median price and count of listings\n",
    "    median_price_by_state_of_building = df.groupby(\"state_of_building\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_state_of_building[\"median_price\"] = median_price_by_state_of_building[\"median_price\"].round(2)\n",
    "\n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_state_of_building, x=\"state_of_building\", y=\"median_price\", color=\"num_listings\", text=\"median_price\", title=\"Price Variation depending on the state of building\", labels={\"state_of_building\": \"State of Building\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_state_of_building[\"median_price\"].max()*1.1])\n",
    "    fig.show()\n",
    "\n",
    "    return df\n",
    "df = price_corr_state_of_building()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a763ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_property_type():\n",
    "    df = clean_and_load()\n",
    "    \n",
    "    # ANOVA: treats postal_code as categorical\n",
    "    model = ols('Q(\"price (€)\") ~ C(type)', data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model)\n",
    "    print(anova_table)\n",
    "\n",
    "    \"\"\" The ANOVA indicates that property type has a highly significant effect on price (p ≈ 1.06e-83), with a very large F-value showing strong differences between types. \n",
    "    However, despite this strong statistical significance, type still explains only part of the total price variability, with most variation coming from other factors.\"\"\"  \n",
    "\n",
    "    # Group by location to compute median price and count of listings\n",
    "    median_price_by_property_type = df.groupby(\"type\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_property_type[\"median_price\"] = median_price_by_property_type[\"median_price\"].round(2)\n",
    "\n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_property_type, x=\"type\", y=\"median_price\", color=\"num_listings\", text=\"median_price\", title=\"Price Variation depending on property type\", labels={\"type\": \"Type\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_property_type[\"median_price\"].max()*1.1])\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    return df\n",
    "df = price_corr_property_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_corr_property_subtype():\n",
    "    df = clean_and_load()\n",
    "    \n",
    "    # ANOVA: treats postal_code as categorical\n",
    "    model = ols('Q(\"price (€)\") ~ C(subtype)', data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model)\n",
    "    print(anova_table)\n",
    "\n",
    "    \"\"\" The ANOVA shows that property subtype has a highly significant effect on price (p ≈ 0.0), with a very large F-value indicating strong differences between subtypes. \n",
    "    Nevertheless, most of the overall price variation remains unexplained, meaning subtype is important but not the primary driver of price.\"\"\"  \n",
    "\n",
    "    # Group by location to compute median price and count of listings\n",
    "    median_price_by_property_subtype = df.groupby(\"subtype\", as_index=False).agg(median_price=(\"price (€)\", \"median\"), num_listings=(\"price (€)\", \"count\"))\n",
    "    median_price_by_property_subtype[\"median_price\"] = median_price_by_property_subtype[\"median_price\"].round(2)\n",
    "\n",
    "    # bar plot\n",
    "    fig = px.bar(median_price_by_property_subtype, x=\"subtype\", y=\"median_price\", color=\"num_listings\", text=\"median_price\", title=\"Price Variation depending on property subtype\", labels={\"subtype\": \"Subtype\", \"median_price\": \"Median Price (€)\", \"num_listings\": \"Number of Listings\"})\n",
    "    fig.update_traces(texttemplate=\"€%{text:,.0f}\", textposition=\"outside\")\n",
    "    fig.update_yaxes(range=[0, median_price_by_property_subtype[\"median_price\"].max()*1.1])\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    return df\n",
    "df = price_corr_property_subtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d626b",
   "metadata": {},
   "source": [
    "Conclusion: \n",
    "Top 5 mst important variables influencing the price: \n",
    "- Living area (corr. = **0.57**)\n",
    "- Number of Bedrooms (corr. = **0.43**)\n",
    "- Terrace area (corr. = **0.43**)\n",
    "- Swimming pool (corr. = **0.25**)\n",
    "- Number of facades (corr. = **0.23**)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
